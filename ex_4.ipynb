{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Neural Network Optimization Methods\n",
    "\n",
    "## A Study of SGD, Adam, and L-BFGS Convergence Behavior on the Friedman Dataset\n",
    "\n",
    "**Overview:**\n",
    "This notebook explores the performance characteristics of different optimization algorithms (SGD, Adam, L-BFGS) \n",
    "\n",
    "**Key Objectives:**\n",
    "- Compare convergence rates of different optimizers\n",
    "- Analyze the impact of different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 1\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Configure hardware settings (CPU/GPU)\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Configuration\n",
    "\n",
    "The Friedman dataset is a synthetic dataset commonly used for regression problems and benchmarking machine learning algorithms.\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- **Type**: Synthetic regression dataset\n",
    "- **Features**: {N_FEATURES} input features, but only 5 are actually used in the target function\n",
    "- **Target Function**: y = 10 * sin(πx₁x₂) + 20(x₃ - 0.5)² + 10x₄ + 5x₅ + ε\n",
    "- **Noise (ε)**: Gaussian noise with standard deviation {NOISE_LEVEL}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration\n",
    "\n",
    "# Define parameters for the Friedman dataset\n",
    "N_SAMPLES = 10000  # Total number of data points to generate\n",
    "N_FEATURES = 16  # Dimensionality of input features\n",
    "NOISE_LEVEL = 0.001  # Amount of noise added to make the problem more realistic\n",
    "\n",
    "# Generate the Friedman dataset\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_friedman1(n_samples=N_SAMPLES, n_features=N_FEATURES, noise=NOISE_LEVEL, random_state=RANDOM_SEED)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# # Generate linear regression dataset\n",
    "\n",
    "# X = np.random.randn(N_SAMPLES, N_FEATURES)\n",
    "# w = np.random.randn(N_FEATURES)\n",
    "# b = np.random.randn()\n",
    "# y = X @ w + b + np.random.randn(N_SAMPLES) * NOISE_LEVEL\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=RANDOM_SEED\n",
    "# )\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train).reshape(-1, 1)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test).reshape(-1, 1)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture Implementation\n",
    "Implement SimpleMLP class - a basic 2-layer neural network with configurable hidden layer size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Implementation\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size=N_FEATURES, hidden_size=64, seed=RANDOM_SEED):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        # self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model to verify\n",
    "model = SimpleMLP().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation and Preprocessing\n",
    "Generate Friedman dataset, split into train/test sets, and prepare PyTorch DataLoaders for efficient batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for PyTorch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print DataLoader information\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of testing batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Framework Implementation\n",
    "Define model evaluation function and main training loop with support for different optimizers (SGD, Adam, LBFGS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Framework Implementation\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# Main training function\n",
    "def train_network(optimizer_name, model_class=SimpleMLP, hidden_size=64, max_time=300):\n",
    "    gc.collect()\n",
    "\n",
    "    model = model_class(hidden_size=hidden_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    eval_count = 0\n",
    "\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    elif optimizer_name == \"LBFGS\":\n",
    "        optimizer = optim.LBFGS(model.parameters(), lr=0.05)\n",
    "\n",
    "    num_epochs = 10000\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    timestamps = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=f\"Training with {optimizer_name}\"):\n",
    "        current_time = time.time() - start_time\n",
    "        if current_time > max_time:\n",
    "            print(f\"Stopping training: exceeded time limit of {max_time} seconds\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        test_loss = evaluate_model(model, test_loader)\n",
    "\n",
    "        if optimizer_name == \"LBFGS\":\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                total_loss = 0\n",
    "                nonlocal running_loss, eval_count\n",
    "                eval_count += 1\n",
    "\n",
    "                for data, target in train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    total_loss += loss.item()\n",
    "                    running_loss += loss.item()\n",
    "                running_loss = running_loss / len(train_loader)\n",
    "                return total_loss\n",
    "\n",
    "            optimizer.step(closure)\n",
    "        else:\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                eval_count += 1\n",
    "\n",
    "            running_loss = running_loss / len(train_loader)\n",
    "\n",
    "        train_loss = running_loss\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        timestamps.append(current_time)\n",
    "\n",
    "        if optimizer_name == \"LBFGS\" and epoch % 5 == 0:\n",
    "            print(f\"{optimizer_name} Epoch {epoch}: Train MSE={train_loss:.6f}, Test MSE={test_loss:.6f}, Time={current_time:.2f}s\")\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    return train_losses, test_losses, training_time, eval_count, timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Comparison Experiment\n",
    "Implement parameter sweep experiment to compare optimizers across different network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer Comparison Experiment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to plot convergence comparison\n",
    "def plot_convergence_comparison(optimizer_results, hidden_size):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for opt_name, (train_losses, test_losses, _, _, timestamps) in optimizer_results.items():\n",
    "        plt.plot(timestamps, train_losses, \"-\", label=f\"{opt_name} (train)\")\n",
    "\n",
    "    plt.title(f\"Training Loss Convergence - Hidden Size {hidden_size}\")\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Main experiment function\n",
    "def parameter_sweep_experiment(hidden_sizes=[16, 64, 256, 1024], max_time=20):\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for hidden_size in hidden_sizes:\n",
    "        print(f\"\\nExperimenting with hidden_size={hidden_size}\")\n",
    "        current_results = {}\n",
    "\n",
    "        for opt in [\"LBFGS\", \"SGD\", \"Adam\"]:\n",
    "            try:\n",
    "                print(f\"\\nTraining {opt} with hidden_size={hidden_size}\")\n",
    "                train_losses, test_losses, training_time, eval_count, timestamps = train_network(opt, hidden_size=hidden_size, max_time=max_time)\n",
    "\n",
    "                current_results[opt] = (train_losses, test_losses, training_time, eval_count, timestamps)\n",
    "\n",
    "                results[opt].append({\n",
    "                    \"hidden_size\": hidden_size,\n",
    "                    \"final_train_mse\": train_losses[-1],\n",
    "                    \"final_test_mse\": test_losses[-1],\n",
    "                    \"training_time\": training_time,\n",
    "                    \"eval_count\": eval_count,\n",
    "                })\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error training with {opt}: {e}\")\n",
    "                continue\n",
    "\n",
    "        plot_convergence_comparison(current_results, hidden_size)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to plot parameter sweep results\n",
    "def plot_parameter_sweep_results(results):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    for opt in results:\n",
    "        hidden_sizes = [r[\"hidden_size\"] for r in results[opt]]\n",
    "        mse = [r[\"final_test_mse\"] for r in results[opt]]\n",
    "        plt.plot(hidden_sizes, mse, \"o-\", label=opt)\n",
    "    plt.xlabel(\"Hidden Layer Size\")\n",
    "    plt.ylabel(\"Final Test MSE\")\n",
    "    plt.title(\"Model Size vs MSE\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the parameter sweep experiment\n",
    "print(\"\\nStarting parameter sweep experiment...\")\n",
    "sweep_results = parameter_sweep_experiment()\n",
    "plot_parameter_sweep_results(sweep_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Explore the Experimental Setup\n",
    "1. Review the provided code and understand the dataset, model architecture, and training setup.\n",
    "2. Run the code and observe the results.\n",
    "3. Identify key parameters that might influence the performance of SGD, Adam, and L-BFGS.  \n",
    "4. Document your hypotheses in a table, make a hypothesis of how these parameters affect the algorithms' performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 2: Test Your Hypotheses\n",
    "1. Modify one parameter at a time (e.g., dataset size, noise level, hidden size) and observe how the results change.\n",
    "2. Compare the outcomes with your hypotheses. Were your predictions correct? Explain why or why not.\n",
    "3. Reflect on which optimization problems or setups might suit each algorithm better and why.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 3: Linear Regression Analysis\n",
    "1. Uncomment the code for generating the linear regression dataset.\n",
    "2. Repeat the steps from Task 1 and Task 2 using this simpler dataset.\n",
    "3. Compare how the optimizers behave on linear regression versus the Friedman dataset and note any differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
